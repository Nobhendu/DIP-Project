{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DRIVE dataset\n",
    "dataset = Path('data/DRIVE')\n",
    "\n",
    "# Load the training dataset\n",
    "train_images = sorted(dataset.glob('training/images/*.tif'))\n",
    "train_labels = sorted(dataset.glob('training/1st_manual/*.gif'))\n",
    "train_mask = sorted(dataset.glob('training/mask/*.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_images), train_images[:3], train_labels[:3], train_mask[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_images = sorted(dataset.glob('test/images/*.tif'))\n",
    "test_mask = sorted(dataset.glob('test/mask/*.gif'))\n",
    "len(test_images), test_images[:3], test_mask[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample image, mask and label\n",
    "image = Image.open(train_images[0])\n",
    "mask = Image.open(train_mask[0])\n",
    "label = Image.open(train_labels[0])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(131)\n",
    "plt.imshow(image)\n",
    "plt.title(f'Image {image.size}, {image.mode}')\n",
    "plt.subplot(132)\n",
    "plt.imshow(mask, cmap='gray')\n",
    "plt.title(f'Mask {mask.size}, {mask.mode}')\n",
    "plt.subplot(133)\n",
    "plt.imshow(label, cmap='gray')\n",
    "plt.title(f'Label {label.size}, {label.mode}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the image in R,G,B channels\n",
    "red, green, blue = image.split()\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(141)\n",
    "plt.imshow(image)\n",
    "plt.subplot(142)\n",
    "plt.imshow(red)\n",
    "plt.title('red')\n",
    "plt.subplot(143)\n",
    "plt.imshow(green)\n",
    "plt.title('green')\n",
    "plt.subplot(144)\n",
    "plt.imshow(blue)\n",
    "plt.title('blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the preprocessing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing training images\n",
    "\n",
    "# 1. take only the green channel\n",
    "# 2. apply morphological opening with a three-pixel diameter disk structuring element\n",
    "# 3. The local background gray level is computed by applying a 69Ã—69 mean filter to the image. The\n",
    "# background is then subtracted and the resulting gray levels are scaled from 0 to 1.\n",
    "# 4. a constant is added to the image gray levels so the mode gray level value in image is set to 0.5\n",
    "# 5.  top-hat transformation on the complement of the image using an eight-pixel radius\n",
    "# disk as the structuring element\n",
    "# \n",
    "from skimage import morphology\n",
    "from skimage import exposure\n",
    "from skimage import filters\n",
    "from skimage import img_as_float, img_as_ubyte\n",
    "from skimage import transform\n",
    "\n",
    "def preprocess(image, mask):\n",
    "    # Convert the image and mask to float32 tensors\n",
    "    image = img_as_float(image)\n",
    "    mask = img_as_float(mask)\n",
    "    \n",
    "    # Take only the green channel\n",
    "    image = image[:, :, 1]\n",
    "    \n",
    "    # Apply morphological opening with a 3-pixel disk structuring element\n",
    "    selem = morphology.disk(3)\n",
    "    image = morphology.opening(image, selem)\n",
    "    \n",
    "    # Compute the local mean of the image\n",
    "    local_mean = filters.rank.mean(image, selem)\n",
    "    \n",
    "    # Subtract the local mean from the image\n",
    "    image = image - local_mean\n",
    "    \n",
    "    # Scale the image so that its values range from 0 to 1\n",
    "    image = exposure.rescale_intensity(image)\n",
    "    \n",
    "    # Add a constant to the image so that its minimum value is 0\n",
    "    image = image - image.min()\n",
    "    \n",
    "    # Normalize the image so its values sum to 1\n",
    "    image = image / image.sum()\n",
    "    \n",
    "    # Apply a top-hat transformation to the image\n",
    "    selem = morphology.disk(8)\n",
    "    image = morphology.white_tophat(image, selem)\n",
    "    \n",
    "    # Normalize the image so its values sum to 1\n",
    "    image = image / image.sum()\n",
    "    \n",
    "    # Apply the mask to the image\n",
    "    image = image * mask\n",
    "    \n",
    "    # # Convert the image and the mask to PyTorch tensors\n",
    "    # image = torch.from_numpy(image).unsqueeze(0)\n",
    "    # mask = torch.from_numpy(mask).unsqueeze(0)\n",
    "    image = cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    image = img_as_ubyte(image)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_image = preprocess(image, mask)\n",
    "print(p_image.shape)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(121)\n",
    "plt.title(f'Preprocessed image {p_image.shape}')\n",
    "plt.imshow(p_image, cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.title(f'ground truth {label.size}')\n",
    "plt.imshow(label, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the image histogram\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.title('Preprocessed image histogram')\n",
    "plt.hist(p_image.ravel(), bins=256)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction from preprocessed image\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "\n",
    "windows = sliding_window_view(p_image, (9, 9))\n",
    "windows.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_windows = sliding_window_view(label, (9, 9))\n",
    "label_windows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the windows randomly\n",
    "\n",
    "plt.figure(figsize=(80, 16))\n",
    "for i in range(40):\n",
    "    xidx = random.randint(0, windows.shape[0]-1)\n",
    "    yidx = random.randint(0, windows.shape[1]-1)\n",
    "\n",
    "    if i < 20:\n",
    "        plt.subplot(4, 20, i+1)\n",
    "        plt.imshow(windows[xidx, yidx], cmap='gray')\n",
    "\n",
    "        plt.subplot(4, 20, i+21)\n",
    "        plt.imshow(label_windows[xidx, yidx], cmap='gray')\n",
    "\n",
    "        if i == 0:\n",
    "            plt.title(f'window {xidx}, {yidx}')\n",
    "            plt.title(f'label {xidx}, {yidx}')\n",
    "\n",
    "    if i >= 20:\n",
    "        plt.subplot(4, 20, i-20+41)\n",
    "        plt.imshow(windows[xidx, yidx], cmap='gray')\n",
    "\n",
    "        plt.subplot(4, 20, i-20+61)\n",
    "        plt.imshow(label_windows[xidx, yidx], cmap='gray')\n",
    "\n",
    "        if i == 20:\n",
    "            plt.title(f'window {xidx}, {yidx}')\n",
    "            plt.title(f'label {xidx}, {yidx}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the features of the image\n",
    "# for each image in the dataset, implement the below steps\n",
    "# 1. take the image and mask and preprocess the image\n",
    "# 2. Compute the following features on the preprocessed image, in a 9x9 window around each pixel in the image.\n",
    "#    - raw pixels i.e. 81 features\n",
    "\n",
    "def extract_features(p_image):\n",
    "    # Compute the window\n",
    "    windows = sliding_window_view(p_image, (9, 9)).copy()\n",
    "    features = windows.reshape(windows.shape[0], windows.shape[1], -1)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_labels(label):\n",
    "    # Compute the window\n",
    "    windows = sliding_window_view(label, (9, 9)).copy()\n",
    "\n",
    "    # pixel centers\n",
    "    centers = windows[:, :, 4, 4]\n",
    "\n",
    "    # labels\n",
    "    labels = (centers > 0).astype(np.uint8)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_values = extract_labels(label)\n",
    "label.size, label_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_path, mask_path, label_path in zip(train_images, train_mask, train_labels):\n",
    "    print(image_path, mask_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = []\n",
    "\n",
    "for image_path, mask_path in zip(train_images, train_mask):\n",
    "    image = Image.open(image_path)\n",
    "    mask = Image.open(mask_path)\n",
    "\n",
    "    p_image = preprocess(image, mask)\n",
    "    print(p_image.shape)\n",
    "    features = extract_features(p_image)\n",
    "    print(features.shape)\n",
    "    train_features.append(features)\n",
    "    print(f'Extracted {features.shape} features from {image_path.name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = []\n",
    "for label_path in train_labels:\n",
    "    labels = extract_labels(label)\n",
    "    print(labels.shape)\n",
    "    train_y.append(labels)\n",
    "    print(f'Extracted {labels.shape} labels from {label_path.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.stack(train_features), np.stack(train_y)\n",
    "train_set[0].shape, train_set[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all images in test set, extract the features\n",
    "test_features = []\n",
    "for image_path, mask_path in zip(test_images, test_mask):\n",
    "    image = Image.open(image_path)\n",
    "    mask = Image.open(mask_path)\n",
    "\n",
    "    p_image = preprocess(image, mask)\n",
    "    features = extract_features(p_image)\n",
    "    test_features.append(features)\n",
    "    print(f'Extracted {features.shape} features from {image_path.name}')\n",
    "\n",
    "test_set = np.stack(test_features)\n",
    "test_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the train_set and test_set\n",
    "\n",
    "np.savez_compressed('data/DRIVE2/train_set.npz', X=train_set[0], y=train_set[1])\n",
    "np.savez_compressed('data/DRIVE2/test_set.npz', X=test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling postive and negative examples from train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train_set and test_set\n",
    "train_set = np.load('data/DRIVE2/train_set.npz', allow_pickle=True)\n",
    "test_set = np.load('data/DRIVE2/test_set.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['X'].shape, train_set['y'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(train_set['y'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_set['y'].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive samples\n",
    "pos_samples = train_set['X'][train_set['y'] == 1]\n",
    "pos_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the std of positive samples\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(pos_samples[:, -1].ravel(), bins=100)\n",
    "plt.title('std of positive samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance of negative samples\n",
    "\n",
    "neg_samples = train_set['X'][train_set['y'] == 0]\n",
    "neg_samples.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the std of negative samples\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(neg_samples[:, -1].ravel(), bins=100)\n",
    "plt.title('std of negative samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling the negative samples equal to the number of positive samples\n",
    "sample_neg_idx = np.random.choice(np.arange(neg_samples.shape[0]), size=train_set['y'].sum())\n",
    "sample_neg = neg_samples[sample_neg_idx]\n",
    "sample_neg.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the std of negative samples\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(sample_neg[:, -1].ravel(), bins=100)\n",
    "plt.title('std of negative samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a balanced dataset for training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balanced dataset = positive samples + negative samples\n",
    "balanced_x = np.concatenate([pos_samples, sample_neg], axis=0)\n",
    "balanced_y = np.concatenate([np.ones(pos_samples.shape[0]), np.zeros(sample_neg.shape[0])], axis=0)\n",
    "balanced_x.shape, balanced_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(121)\n",
    "plt.hist(balanced_x[:, -1].ravel(), bins=100)\n",
    "plt.subplot(122)\n",
    "plt.hist(balanced_y.ravel())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling of balanced_x\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "balanced_x = scaler.fit_transform(balanced_x.reshape(-1, 81)).reshape(balanced_x.shape)\n",
    "balanced_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(balanced_x[:, -1].ravel(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_y.sum(), np.unique(balanced_y, return_counts=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('data/DRIVE2/balanced_train_set.npz', X=balanced_x, y=balanced_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Neural Network using MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch dataloader for balanced data\n",
    "\n",
    "class DRIVE(Dataset):\n",
    "    def __init__(self, data_percentage=1.0):\n",
    "        super().__init__()\n",
    "        balanced_set = np.load('data/DRIVE2/balanced_train_set.npz')\n",
    "        M = int(balanced_set['X'].shape[0] * data_percentage)\n",
    "\n",
    "        samples = np.random.choice(np.arange(balanced_set['X'].shape[0]), size=M)\n",
    "        self.X = balanced_set['X'][samples].astype(np.float32)\n",
    "        self.y = balanced_set['y'].reshape(-1,1)[samples].astype(np.float32)\n",
    "\n",
    "        print('Loaded the dataset', self.X.shape, self.X.dtype, self.y.shape, self.y.dtype)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP with 5 inputs, three hidden layers with 15 nodes each, and one output\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=81, hidden_size=[15,15,15], output_size=1, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.p_dropout = dropout\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size[0])\n",
    "        for i in range(1, len(hidden_size)):\n",
    "            setattr(self, f'fc{i+1}', nn.Linear(hidden_size[i-1], hidden_size[i]))\n",
    "        self.fc4 = nn.Linear(hidden_size[-1], output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu6(self.fc1(x))\n",
    "        x = F.relu6(self.fc2(x))\n",
    "        x = F.relu6(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 10\n",
    "BATCH_SIZE = 1024\n",
    "lr = 0.01\n",
    "\n",
    "train_set = DRIVE(data_percentage=0.1)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    for batch_num, input_data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x, y = input_data\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_num % 40 == 0:\n",
    "            print('\\tEpoch %d | Batch %d | Loss %6.2f' % (epoch, batch_num, loss.item()))\n",
    "    print('Epoch %d | Loss %6.2f' % (epoch, sum(losses)/len(losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Pytorch Lightning for training the MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import lightning as L\n",
    "from torchmetrics import Accuracy, Precision, Recall\n",
    "\n",
    "class MLPLightning(L.LightningModule):\n",
    "    def __init__(self, input_size=81, hidden_size=[15,15,15], output_size=1, learning_rate=0.01, threshold=0.7):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.lr = learning_rate\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size[0])\n",
    "        for i in range(1, len(hidden_size)):\n",
    "            setattr(self, f'fc{i+1}', nn.Linear(hidden_size[i-1], hidden_size[i]))\n",
    "        self.fc4 = nn.Linear(hidden_size[-1], output_size)\n",
    "        self.acc = Accuracy(task='binary', threshold=threshold)\n",
    "        self.precision = Precision(task='binary', threshold=threshold)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu6(self.fc1(x))\n",
    "        x = F.relu6(self.fc2(x))\n",
    "        x = F.relu6(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # print('train', x.shape, y.shape, x.dtype, y.dtype)\n",
    "        output = self(x)\n",
    "        loss = F.binary_cross_entropy(output, y)\n",
    "        acc = self.acc(output, y)\n",
    "\n",
    "        self.log_dict({'train_loss': loss, 'train_acc': acc})\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # print('val', x.shape, y.shape, x.dtype, y.dtype)\n",
    "        output = self(x)\n",
    "        loss = F.binary_cross_entropy(output, y)\n",
    "        acc = self.acc(output, y)\n",
    "        self.log_dict({'val_loss': loss, 'val_acc': acc})\n",
    "        return loss\n",
    "    \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        output = self(x)\n",
    "        return output\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=self.lr, momentum=0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, min_lr=1e-4)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss'\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the PyTorch Lightning Trainer to train the model\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "MAX_STEPS = 100 * 800\n",
    "BATCH_SIZE = 2048 # Maximum batch size that fits on the GPU\n",
    "SPLIT = 0.8\n",
    "lr = 0.001\n",
    "\n",
    "# use 20% of training data for validation\n",
    "trainval_set = DRIVE(data_percentage=0.5)\n",
    "train_set_size = int(len(trainval_set) * SPLIT)\n",
    "val_set_size = len(trainval_set) - train_set_size\n",
    "print('training set:', train_set_size, 'validation set:', val_set_size)\n",
    "\n",
    "epochs = int(MAX_STEPS * BATCH_SIZE / train_set_size)\n",
    "print('training steps:', train_set_size * epochs // BATCH_SIZE)\n",
    "\n",
    "# split the train set into two\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, val_set = random_split(trainval_set, [train_set_size, val_set_size], generator=seed)\n",
    "\n",
    "# data loaders\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=100000, shuffle=False)\n",
    "\n",
    "# create the model and train\n",
    "model = MLPLightning()\n",
    "\n",
    "callbacks = [\n",
    "    L.pytorch.callbacks.LearningRateMonitor(logging_interval='step'),\n",
    "    L.pytorch.callbacks.ModelCheckpoint(monitor='val_loss'),\n",
    "    L.pytorch.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "]\n",
    "trainer = L.Trainer(default_root_dir=\"models/mlpL2\", max_epochs=epochs, callbacks=callbacks)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# final eval score\n",
    "trainer.validate(model, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'data/DRIVE2/model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Prediction of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MLPLightning.load_from_checkpoint('models/mlpL2/lightning_logs/version_0/checkpoints/epoch=25-step=5018.ckpt')\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training used a balanced dataset. For prediction we will use the full dataset train_set\n",
    "\n",
    "class PredictDrive(Dataset):\n",
    "    def __init__(self, num_samples=20):\n",
    "        super().__init__()\n",
    "        full_set = np.load('data/DRIVE2/train_set.npz')\n",
    "        data_samples = full_set['X'].shape[0]\n",
    "\n",
    "        self.feature_shape = (min(num_samples, data_samples),) + full_set['X'].shape[1:]\n",
    "        self.X = full_set['X'][:num_samples].reshape(-1,81).astype(np.float32)\n",
    "        self.y = full_set['y'][:num_samples].reshape(-1,1).astype(np.float32)\n",
    "\n",
    "        print(f'Loaded the dataset {self.feature_shape}', self.X.shape, self.X.dtype, self.y.shape, self.y.dtype)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_set = PredictDrive(num_samples=20)\n",
    "predict_loader = DataLoader(predict_set, batch_size=len(predict_set), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer()\n",
    "prediction = trainer.predict(model, predict_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y = prediction[0].numpy().reshape(predict_set.feature_shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.hist(predicted_y[0].ravel(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.histogram(predicted_y[0].ravel(), bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the 20 images in the test set\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i+1)\n",
    "    plt.imshow(predicted_y[i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predicted_y[i].ravel(), bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the predictions to npy for hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/krishna.py/code/iiit-h_pdm_dip/final-project/segmentation2.ipynb Cell 66\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/krishna.py/code/iiit-h_pdm_dip/final-project/segmentation2.ipynb#Y123sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m20\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/krishna.py/code/iiit-h_pdm_dip/final-project/segmentation2.ipynb#Y123sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     padded_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mpad(predicted_y[i], \u001b[39m4\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m'\u001b[39m, constant_values\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/krishna.py/code/iiit-h_pdm_dip/final-project/segmentation2.ipynb#Y123sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     np\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/DRIVE2/predicted/yhat_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m21\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m, padded_pred)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    padded_pred = np.pad(predicted_y[i], 4, mode='constant', constant_values=0)\n",
    "    np.save(f'data/DRIVE2/predicted/yhat_{i+21}.npy', padded_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
